{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "# Split data with stratified cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# keras Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Encoding of classifications\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a few constants to keep track of\n",
    "random_state=1\n",
    "path='../../tor_dataset/Scenario-B/'\n",
    "dep_var = 'class'\n",
    "num_classes=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(filename='', verbose=False):\n",
    "    \"\"\"\n",
    "        This function takes a filename, loads the data into a dataframe, then separates the classification data\n",
    "        \n",
    "        args:\n",
    "            filename => str, path to csv file to be loaded\n",
    "            \n",
    "        returns:\n",
    "            list(X,y) => data, classifications\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Before encoding and splitting:')\n",
    "        print(df.head())\n",
    "    \n",
    "    # Actual data\n",
    "    X = df.loc[:, df.columns != dep_var]\n",
    "    \n",
    "    # Set number of classes we see\n",
    "    num_classes = df[dep_var].nunique()\n",
    "    \n",
    "    # Classifications\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df[dep_var])\n",
    "    \n",
    "    if verbose:\n",
    "        print('Classification encoding:')\n",
    "        for i in range(len(encoder.classes_)):\n",
    "            print('\\t{} => {}'.format(i, encoder.classes_[i]))\n",
    "        \n",
    "        print('After encoding and splitting:')\n",
    "        print('X = ')\n",
    "        print(X.head())\n",
    "        print('\\ny = ')\n",
    "        print(y[:5])\n",
    "    \n",
    "    # X holds the data while y holds the classifications\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network model training and evaluation\n",
    "def build_fit_eval(opt, act):\n",
    "    # All of the data files\n",
    "    files=['TimeBasedFeatures-15s-Layer2.csv',\n",
    "          'TimeBasedFeatures-30s-Layer2.csv',\n",
    "          'TimeBasedFeatures-60s-Layer2.csv',\n",
    "          'TimeBasedFeatures-120s-Layer2.csv']\n",
    "\n",
    "    # Lists for accuracies collected from models\n",
    "    list_dnn = []\n",
    "\n",
    "    for file in files:\n",
    "        # Load in the data\n",
    "        X, y = get_Xy(path + file)\n",
    "\n",
    "        # Mean accuracies for each model\n",
    "        mean_dnn = 0\n",
    "\n",
    "        # 10-fold Stratified Cross-Validation\n",
    "        n_splits = 10\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        for train_idxs, test_idxs in skf.split(X, y):\n",
    "            # Define the training and testing sets\n",
    "            X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "            y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "\n",
    "            # Create a different version of the y_train and y_test for the Deep Neural Network\n",
    "            y_train_dnn = to_categorical(y_train, num_classes=num_classes)\n",
    "            y_test_dnn = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "            # Deep Neural Network\n",
    "            dnn = Sequential([\n",
    "                Dense(64, input_shape=(23,)),\n",
    "                Dense(8, activation=act)\n",
    "            ])\n",
    "            dnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Train the models\n",
    "            dnn.fit(x=X_train, y=y_train_dnn, epochs=10, batch_size=10, verbose=0, validation_data=(X_test, y_test_dnn))\n",
    "\n",
    "            # This returns [loss, accuracy]\n",
    "            results_dnn = dnn.evaluate(X_test, y_test_dnn, verbose=0)\n",
    "\n",
    "            # Add the results to the running mean\n",
    "            mean_dnn += results_dnn[1] / (n_splits * 1.0)\n",
    "\n",
    "        # Push the mean results from all of the splits to the lists\n",
    "        list_dnn.append(mean_dnn)\n",
    "    \n",
    "    return list_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers=[\n",
    "    'SGD',\n",
    "    'RMSprop',\n",
    "    'Adam',\n",
    "    'Adadelta',\n",
    "    'Adagrad',\n",
    "    'Adamax',\n",
    "    'Nadam'\n",
    "]\n",
    "activations=[\n",
    "    'relu',\n",
    "    'sigmoid',\n",
    "    'softmax',\n",
    "    'softplus',\n",
    "    'softsign',\n",
    "    'tanh',\n",
    "    'selu',\n",
    "    'elu',\n",
    "    'exponential'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer\tActivation\tAccuracies (%)\n",
      "\n",
      "SGD\t\trelu\t\t33.99\t34.83\t26.99\t18.12\n",
      "\t\tsigmoid\t\t5.09\t8.48\t4.59\t4.31\n",
      "\t\tsoftmax\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\tsoftplus\t\t22.71\t31.86\t36.44\t23.42\n",
      "\t\tsoftsign\t\t3.10\t2.16\t5.43\t5.94\n",
      "\t\ttanh\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\tselu\t\t36.52\t21.64\t33.78\t30.93\n",
      "\t\telu\t\t33.60\t31.72\t32.58\t23.34\n",
      "\t\texponential\t\t1.37\t1.77\t2.35\t3.28\n",
      "RMSprop\t\trelu\t\t5.80\t20.60\t28.00\t11.11\n",
      "\t\tsigmoid\t\t4.85\t3.21\t5.23\t5.94\n",
      "\t\tsoftmax\t\t48.63\t50.37\t50.34\t44.43\n",
      "\t\tsoftplus\t\t8.42\t11.18\t35.87\t32.14\n",
      "\t\tsoftsign\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\ttanh\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\tselu\t\t21.22\t20.74\t28.71\t40.06\n",
      "\t\telu\t\t25.45\t27.61\t41.24\t38.54\n",
      "\t\texponential\t\t1.37\t1.77\t2.35\t3.28\n",
      "Adam\t\trelu\t\t24.11\t42.43\t39.23\t33.55\n",
      "\t\tsigmoid\t\t3.21\t7.70\t3.94\t5.75\n",
      "\t\tsoftmax\t\t61.28\t49.57\t55.13\t47.54\n",
      "\t\tsoftplus\t\t31.16\t30.87\t42.18\t33.16\n",
      "\t\tsoftsign\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\ttanh\t\t1.37\t1.88\t2.99\t3.28\n",
      "\t\tselu\t\t37.02\t35.95\t35.43\t35.40\n",
      "\t\telu\t\t47.71\t39.26\t37.50\t33.16\n",
      "\t\texponential\t\t1.37\t1.77\t2.35\t3.28\n",
      "Adadelta\t\trelu\t\t7.53\t27.89\t43.53\t35.73\n",
      "\t\tsigmoid\t\t3.63\t2.94\t4.17\t6.37\n",
      "\t\tsoftmax\t\t46.07\t52.82\t44.90\t46.11\n",
      "\t\tsoftplus\t\t5.60\t14.22\t37.48\t38.55\n",
      "\t\tsoftsign\t\t2.83\t2.05\t4.92\t6.54\n",
      "\t\ttanh\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\tselu\t\t27.17\t36.44\t32.06\t38.94\n",
      "\t\telu\t\t22.86\t26.53\t42.41\t39.80\n",
      "\t\texponential\t\t1.37\t1.77\t2.35\t3.28\n",
      "Adagrad\t\trelu\t\t35.60\t33.46\t20.02\t39.15\n",
      "\t\tsigmoid\t\t5.63\t4.11\t4.59\t4.52\n",
      "\t\tsoftmax\t\t47.77\t35.22\t39.27\t46.33\n",
      "\t\tsoftplus\t\t31.73\t34.06\t36.17\t38.76\n",
      "\t\tsoftsign\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\ttanh\t\t1.37\t2.39\t2.35\t3.28\n",
      "\t\tselu\t\t39.76\t42.47\t35.90\t42.64\n",
      "\t\telu\t\t43.39\t31.20\t37.42\t34.86\n",
      "\t\texponential\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notclaytonjohnson/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.122851). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1.37\t1.77\t2.35\t3.28\n",
      "Adamax\t\trelu\t\t26.52\t27.12\t43.50\t34.67\n",
      "\t\tsigmoid\t\t3.75\t5.44\t4.92\t9.49\n",
      "\t\tsoftmax\t\t58.96\t51.04\t47.78\t40.54\n",
      "\t\tsoftplus\t\t25.92\t35.45\t34.07\t42.50\n",
      "\t\tsoftsign\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\ttanh\t\t1.85\t2.27\t2.35\t4.12\n",
      "\t\tselu\t\t33.63\t35.38\t33.60\t39.81\n",
      "\t\telu\t\t33.63\t32.00\t41.69\t30.51\n",
      "\t\texponential\t\t1.37\t1.77\t2.35\t3.28\n",
      "Nadam\t\trelu\t\t32.11\t42.30\t28.65\t32.73\n",
      "\t\tsigmoid\t\t3.75\t4.38\t6.52\t5.55\n",
      "\t\tsoftmax\t\t49.26\t44.91\t41.21\t29.80\n",
      "\t\tsoftplus\t\t34.40\t37.25\t33.25\t40.75\n",
      "\t\tsoftsign\t\t1.37\t1.77\t2.35\t3.28\n",
      "\t\ttanh\t\t1.37\t1.77\t2.35\t4.12\n",
      "\t\tselu\t\t36.13\t46.47\t36.87\t36.68\n",
      "\t\telu\t\t42.53\t47.43\t31.91\t39.20\n",
      "\t\texponential\t\t1.37\t1.77\t2.35\t3.28\n"
     ]
    }
   ],
   "source": [
    "print('Optimizer\\tActivation\\tAccuracies (%)\\n')\n",
    "for opt in optimizers:\n",
    "    print(opt, end='')\n",
    "    for act in activations:\n",
    "        print('\\t\\t{}\\t'.format(act), end='')\n",
    "        accs = build_fit_eval(opt, act)\n",
    "        for acc in accs:\n",
    "            print('\\t{:.2f}'.format(100*acc), end='')\n",
    "        print('\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
