{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "# Split data with stratified cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# keras Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Encoding of classifications\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a few constants to keep track of\n",
    "random_state=1\n",
    "path='../../tor_dataset/Scenario-B/'\n",
    "dep_var = 'class'\n",
    "num_classes=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(filename='', verbose=False):\n",
    "    \"\"\"\n",
    "        This function takes a filename, loads the data into a dataframe, then separates the classification data\n",
    "        \n",
    "        args:\n",
    "            filename => str, path to csv file to be loaded\n",
    "            \n",
    "        returns:\n",
    "            list(X,y) => data, classifications\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Before encoding and splitting:')\n",
    "        print(df.head())\n",
    "    \n",
    "    # Actual data\n",
    "    X = df.loc[:, df.columns != dep_var]\n",
    "    \n",
    "    # Set number of classes we see\n",
    "    num_classes = df[dep_var].nunique()\n",
    "    \n",
    "    # Classifications\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df[dep_var])\n",
    "    \n",
    "    if verbose:\n",
    "        print('Classification encoding:')\n",
    "        for i in range(len(encoder.classes_)):\n",
    "            print('\\t{} => {}'.format(i, encoder.classes_[i]))\n",
    "        \n",
    "        print('After encoding and splitting:')\n",
    "        print('X = ')\n",
    "        print(X.head())\n",
    "        print('\\ny = ')\n",
    "        print(y[:5])\n",
    "    \n",
    "    # X holds the data while y holds the classifications\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network model training and evaluation\n",
    "def build_fit_eval(opt='adam', act='softmax', batch_size=10):\n",
    "    # All of the data files\n",
    "    files=['TimeBasedFeatures-15s-Layer2.csv',\n",
    "          'TimeBasedFeatures-30s-Layer2.csv',\n",
    "          'TimeBasedFeatures-60s-Layer2.csv',\n",
    "          'TimeBasedFeatures-120s-Layer2.csv']\n",
    "\n",
    "    # Lists for accuracies collected from models\n",
    "    list_dnn = []\n",
    "\n",
    "    for file in files:\n",
    "        # Load in the data\n",
    "        X, y = get_Xy(path + file)\n",
    "\n",
    "        # Mean accuracies for each model\n",
    "        mean_dnn = 0\n",
    "\n",
    "        # 10-fold Stratified Cross-Validation\n",
    "        n_splits = 10\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        for train_idxs, test_idxs in skf.split(X, y):\n",
    "            # Define the training and testing sets\n",
    "            X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "            y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "\n",
    "            # Create a different version of the y_train and y_test for the Deep Neural Network\n",
    "            y_train_dnn = to_categorical(y_train, num_classes=num_classes)\n",
    "            y_test_dnn = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "            # Deep Neural Network\n",
    "            dnn = Sequential([\n",
    "                Dense(64, input_shape=(23,)),\n",
    "                Dense(8, activation=act)\n",
    "            ])\n",
    "            dnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Train the models\n",
    "            dnn.fit(x=X_train, y=y_train_dnn, epochs=10, batch_size=batch_size, verbose=0, validation_data=(X_test, y_test_dnn))\n",
    "\n",
    "            # This returns [loss, accuracy]\n",
    "            results_dnn = dnn.evaluate(X_test, y_test_dnn, verbose=0)\n",
    "\n",
    "            # Add the results to the running mean\n",
    "            mean_dnn += results_dnn[1] / (n_splits * 1.0)\n",
    "\n",
    "        # Push the mean results from all of the splits to the lists\n",
    "        list_dnn.append(mean_dnn)\n",
    "    \n",
    "    return list_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers=[\n",
    "    'SGD',\n",
    "    'RMSprop',\n",
    "    'Adam',\n",
    "    'Adadelta',\n",
    "    'Adagrad',\n",
    "    'Adamax',\n",
    "    'Nadam'\n",
    "]\n",
    "activations=[\n",
    "    'relu',\n",
    "    'sigmoid',\n",
    "    'softmax',\n",
    "    'softplus',\n",
    "    'softsign',\n",
    "    'tanh',\n",
    "    'selu',\n",
    "    'elu',\n",
    "    'exponential'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('Optimizer\\tActivation\\tAccuracies (%)\\n')\\nfor opt in optimizers:\\n    print(opt, end='')\\n    for act in activations:\\n        print('\\t\\t{}\\t'.format(act), end='')\\n        accs = build_fit_eval(opt, act)\\n        for acc in accs:\\n            print('\\t{:.2f}'.format(100*acc), end='')\\n        print('\\n', end='')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print('Optimizer\\tActivation\\tAccuracies (%)\\n')\n",
    "for opt in optimizers:\n",
    "    print(opt, end='')\n",
    "    for act in activations:\n",
    "        print('\\t\\t{}\\t'.format(act), end='')\n",
    "        accs = build_fit_eval(opt, act)\n",
    "        for acc in accs:\n",
    "            print('\\t{:.2f}'.format(100*acc), end='')\n",
    "        print('\\n', end='')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [10, 15, 20, 25, 30, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size\tAccuracies (%)\t\t\tMean Accuracy (%)\n",
      "10\t\t53.07\t50.68\t44.14\t39.74\t46.91\n",
      "15\t\t57.47\t53.79\t41.33\t41.32\t48.48\n",
      "20\t\t48.81\t50.43\t43.10\t46.12\t47.12\n",
      "25\t\t56.55\t52.62\t43.70\t46.35\t49.81\n",
      "30\t\t54.67\t40.89\t50.09\t41.79\t46.86\n",
      "35\t\t58.51\t49.48\t45.00\t42.85\t48.96\n"
     ]
    }
   ],
   "source": [
    "print('Batch Size\\tAccuracies (%)\\t\\t\\tMean Accuracy (%)')\n",
    "for batch_size in batch_sizes:\n",
    "    print('{}\\t'.format(batch_size), end='')\n",
    "    accs = build_fit_eval(batch_size=batch_size)\n",
    "    for acc in accs:\n",
    "        print('\\t{:.2f}'.format(100*acc), end='')\n",
    "    print('\\t{:.2f}'.format( 100 * sum(accs) / len(accs) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
