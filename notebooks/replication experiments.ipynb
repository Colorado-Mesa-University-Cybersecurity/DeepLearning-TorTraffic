{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Experiments\n",
    "This notebook's goal is to attempt to replicate the experiments presented in Arash *et al.* using the ISCXTor2016 dataset provided by the Canadian Institute for Cybersecurity at the University of New Brunswick (CIC-UNB). The experiments in this work are split into Scenario-A and Scenario-B. Scenario-A's goal is to classify traffic samples as Tor or NonTor, while Scenario-B attempts to classify the type of traffic (FTP, browsing, video and audio-streaming, VoIP, chat, mail, and P2P) seen in Tor samples.   \n",
    "\n",
    "Let's begin with Scenario-A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario-A\n",
    "In these experiments, the team uses three machine learning algorithms: ZeroR, C4.5, and k-Nearest Neighbors. The experiments were originally completed in Weka, however they will attempt to be replicated here using the `sklearn` python library.  \n",
    "\n",
    "The `sklearn` models used will be the following:  \n",
    " - ZeroR &rarr; DummyClassifier\n",
    " - C4.5 &rarr; DecisionTreeClassifier\n",
    " - k-Nearest Neighbor &rarr; KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split data with stratified cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Encoding of classifications\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a few constants to keep track of\n",
    "random_state=1\n",
    "path='../../tor_dataset/Scenario-A/'\n",
    "dep_var = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We have to import the dataset and modify the classification (`y`) so we can hand it to the `sklearn` models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(filename='', verbose=False):\n",
    "    \"\"\"\n",
    "        This function takes a filename, loads the data into a dataframe, then separates the classification data\n",
    "        \n",
    "        args:\n",
    "            filename => str, path to csv file to be loaded\n",
    "            \n",
    "        returns:\n",
    "            list(X,y) => data, classifications\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Before encoding and splitting:')\n",
    "        print(df.head())\n",
    "    \n",
    "    # Actual data\n",
    "    X = df.loc[:, df.columns != dep_var]\n",
    "    \n",
    "    # Classifications\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df[dep_var])\n",
    "    \n",
    "    if verbose:\n",
    "        print('Classification encoding:')\n",
    "        for i in range(len(encoder.classes_)):\n",
    "            print('\\t{} => {}'.format(i, encoder.classes_[i]))\n",
    "        \n",
    "        print('After encoding and splitting:')\n",
    "        print('X = ')\n",
    "        print(X.head())\n",
    "        print('\\ny = ')\n",
    "        print(y[:5])\n",
    "    \n",
    "    # X holds the data while y holds the classifications\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding and splitting:\n",
      "   duration  total_fiat  total_biat  min_fiat  min_biat       max_fiat  \\\n",
      "0   9368711          16           4   1564818   1549373  190205.285714   \n",
      "1   7340238          18           4   1567554   1527893  165686.977273   \n",
      "2   4644225          29          15   1270547   1079974  165865.178571   \n",
      "3   4978735          19           8   2492050   2457286  239543.250000   \n",
      "4  11838189          19          10   3094089   3093543  243766.500000   \n",
      "\n",
      "        max_biat      mean_fiat      mean_biat  flowPktsPerSecond  ...  \\\n",
      "0  203290.456522  389822.391917  370323.719754          10.353612  ...   \n",
      "1  186914.846154  317267.548742  304370.651301          11.580006  ...   \n",
      "2  195302.130435  329473.126261  300492.588227          11.412022  ...   \n",
      "3  276596.388889  612435.304238  628339.573544           8.034169  ...   \n",
      "4  295954.725000  599721.781709  625632.703972           7.602514  ...   \n",
      "\n",
      "     std_flowiat  min_active   mean_active  max_active    std_active  \\\n",
      "0  267600.198443     1871488  1.983656e+06     2195089  1.832197e+05   \n",
      "1  221462.862028     1491627  3.572433e+06     5653239  2.942704e+06   \n",
      "2  217475.425246     1758922  1.758922e+06     1758922  0.000000e+00   \n",
      "3  436959.716436     1710925  2.382905e+06     3054885  9.503232e+05   \n",
      "4  436129.639296     1747431  2.400446e+06     3240696  6.232744e+05   \n",
      "\n",
      "   min_idle  mean_idle  max_idle       std_idle   class  \n",
      "0   1234883  1420565.0   1523088  161096.539275  NONTOR  \n",
      "1   1131498  1324636.0   1517774  273138.379008  NONTOR  \n",
      "2   1079974  1079974.0   1079974       0.000000  NONTOR  \n",
      "3   1346073  1894031.5   2441990  774930.342317  NONTOR  \n",
      "4   1394455  1983227.0   3042717  725987.829075  NONTOR  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Classification encoding:\n",
      "\t0 => NONTOR\n",
      "\t1 => TOR\n",
      "After encoding and splitting:\n",
      "X = \n",
      "   duration  total_fiat  total_biat  min_fiat  min_biat       max_fiat  \\\n",
      "0   9368711          16           4   1564818   1549373  190205.285714   \n",
      "1   7340238          18           4   1567554   1527893  165686.977273   \n",
      "2   4644225          29          15   1270547   1079974  165865.178571   \n",
      "3   4978735          19           8   2492050   2457286  239543.250000   \n",
      "4  11838189          19          10   3094089   3093543  243766.500000   \n",
      "\n",
      "        max_biat      mean_fiat      mean_biat  flowPktsPerSecond  ...  \\\n",
      "0  203290.456522  389822.391917  370323.719754          10.353612  ...   \n",
      "1  186914.846154  317267.548742  304370.651301          11.580006  ...   \n",
      "2  195302.130435  329473.126261  300492.588227          11.412022  ...   \n",
      "3  276596.388889  612435.304238  628339.573544           8.034169  ...   \n",
      "4  295954.725000  599721.781709  625632.703972           7.602514  ...   \n",
      "\n",
      "    mean_flowiat    std_flowiat  min_active   mean_active  max_active  \\\n",
      "0   97590.739583  267600.198443     1871488  1.983656e+06     2195089   \n",
      "1   87383.785714  221462.862028     1491627  3.572433e+06     5653239   \n",
      "2   89312.019231  217475.425246     1758922  1.758922e+06     1758922   \n",
      "3  127659.871795  436959.716436     1710925  2.382905e+06     3054885   \n",
      "4  133013.359551  436129.639296     1747431  2.400446e+06     3240696   \n",
      "\n",
      "     std_active  min_idle  mean_idle  max_idle       std_idle  \n",
      "0  1.832197e+05   1234883  1420565.0   1523088  161096.539275  \n",
      "1  2.942704e+06   1131498  1324636.0   1517774  273138.379008  \n",
      "2  0.000000e+00   1079974  1079974.0   1079974       0.000000  \n",
      "3  9.503232e+05   1346073  1894031.5   2441990  774930.342317  \n",
      "4  6.232744e+05   1394455  1983227.0   3042717  725987.829075  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "y = \n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of how the function operates...\n",
    "X, y = get_Xy(path + 'TimeBasedFeatures-15s-TOR-NonTOR.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for TimeBasedFeatures-15s-TOR-NonTOR.csv...done\n",
      "Training for TimeBasedFeatures-30s-TOR-NonTOR.csv...done\n",
      "Training for TimeBasedFeatures-60s-TOR-NonTOR.csv...done\n",
      "Training for TimeBasedFeatures-120s-TOR-NonTOR.csv...done\n",
      "All trainings complete!\n"
     ]
    }
   ],
   "source": [
    "# All of the data files\n",
    "files=['TimeBasedFeatures-15s-TOR-NonTOR.csv', \n",
    "       'TimeBasedFeatures-30s-TOR-NonTOR.csv', \n",
    "       'TimeBasedFeatures-60s-TOR-NonTOR.csv', \n",
    "       'TimeBasedFeatures-120s-TOR-NonTOR.csv']\n",
    "\n",
    "# Lists for accuracies collected from models\n",
    "list_dummy = []\n",
    "list_dt = []\n",
    "list_knn = []\n",
    "\n",
    "for file in files:\n",
    "    print('Training for {}...'.format(file), end='')\n",
    "    \n",
    "    # Load in the data\n",
    "    X, y = get_Xy(path + file)\n",
    "    \n",
    "    # Mean accuracies for each model\n",
    "    mean_dummy = 0 # This is the worst kind of dummy\n",
    "    mean_dt = 0\n",
    "    mean_knn = 0\n",
    "    \n",
    "    # 10-fold Stratified Cross-Validation\n",
    "    n_splits = 10\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_idxs, test_idxs in skf.split(X, y):\n",
    "        # Define the training and testing sets\n",
    "        X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "        y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "        \n",
    "        # Initialize the models\n",
    "        dummy = DummyClassifier(strategy='most_frequent')\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        # Train the models\n",
    "        dummy.fit(X_train, y_train)\n",
    "        dt.fit(X_train, y_train)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the models\n",
    "        results_dummy = dummy.score(X_test, y_test)\n",
    "        results_dt = dt.score(X_test, y_test)\n",
    "        results_knn = knn.score(X_test, y_test)  \n",
    "        \n",
    "        # Add the results to the running mean\n",
    "        mean_dummy += results_dummy / (n_splits * 1.0)\n",
    "        mean_dt += results_dt / (n_splits * 1.0)\n",
    "        mean_knn += results_knn / (n_splits * 1.0)\n",
    "    \n",
    "    # Push the mean results from all of the splits to the lists\n",
    "    list_dummy.append(mean_dummy)\n",
    "    list_dt.append(mean_dt)\n",
    "    list_knn.append(mean_knn)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "print('All trainings complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Below are the final results in attempting to replicate Scenario-A's experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File\t\t\t\t\tDummy\tDecision Tree\tk-Nearest Neighbor\n",
      "----------------------------------------------------------------------------------\n",
      "TimeBasedFeatures-15s-TOR-NonTOR.csv\t84.99%\t99.91%\t\t99.88%\n",
      "TimeBasedFeatures-30s-TOR-NonTOR.csv\t89.22%\t99.90%\t\t99.93%\n",
      "TimeBasedFeatures-60s-TOR-NonTOR.csv\t94.44%\t99.94%\t\t99.91%\n",
      "TimeBasedFeatures-120s-TOR-NonTOR.csv\t95.82%\t99.96%\t\t99.92%\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print('File\\t\\t\\t\\t\\tDummy\\tDecision Tree\\tk-Nearest Neighbor')\n",
    "print('-'*82)\n",
    "for i in range(len(files)):\n",
    "    print('{}\\t{:.2f}%\\t{:.2f}%\\t\\t{:.2f}%'.format(files[i], 100*list_dummy[i], 100*list_dt[i], 100*list_knn[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the data we see above with the reported metrics...  \n",
    "![Results from Arash *et al.* for Scenario-A](../media/scenarioa_paper.png)  \n",
    "...we clearly see that our results match up with the team's. Despite the fact that we are collected just the accuracy here, we can see that the recall and precision are extremely close than what we are reporting above. In the case of ZeroR, we are seeing the accuracy of our model around the middle between ZeroR's recall and precision metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario-B\n",
    "In these experiments, the team uses three machine learning algorithms: Random Forest, C4.5, and k-Nearest Neighbors. The experiments were originally completed in Weka, however they will attempt to be replicated here using the `sklearn` python library.  \n",
    "\n",
    "The following `sklearn` models will be used:\n",
    " - Random Forest &rarr; RandomForestClassifier\n",
    " - C4.5 &rarr; DecisionTreeClassifier\n",
    " - k-Nearest Neighbors &rarr; KNeighborsClassifier\n",
    " \n",
    " *Much of the process here is similar to what is done in Scenario-A. If you have any questions, please refer to Scenario-A first for any clarification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split data with stratified cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Encoding of classifications\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a few constants to keep track of\n",
    "random_state=1\n",
    "path='../../tor_dataset/Scenario-B/'\n",
    "dep_var = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for TimeBasedFeatures-15s-Layer2.csv...done\n",
      "Training for TimeBasedFeatures-30s-Layer2.csv...done\n",
      "Training for TimeBasedFeatures-60s-Layer2.csv...done\n",
      "Training for TimeBasedFeatures-120s-Layer2.csv...done\n",
      "All trainings complete!\n"
     ]
    }
   ],
   "source": [
    "# All of the data files\n",
    "files=['TimeBasedFeatures-15s-Layer2.csv',\n",
    "      'TimeBasedFeatures-30s-Layer2.csv',\n",
    "      'TimeBasedFeatures-60s-Layer2.csv',\n",
    "      'TimeBasedFeatures-120s-Layer2.csv']\n",
    "\n",
    "# Lists for accuracies collected from models\n",
    "list_rf = []\n",
    "list_dt = []\n",
    "list_knn = []\n",
    "\n",
    "for file in files:\n",
    "    print('Training for {}...'.format(file), end='')\n",
    "    \n",
    "    # Load in the data\n",
    "    X, y = get_Xy(path + file)\n",
    "    \n",
    "    # Mean accuracies for each model\n",
    "    mean_rf = 0 # This is the worst kind of dummy\n",
    "    mean_dt = 0\n",
    "    mean_knn = 0\n",
    "    \n",
    "    # 10-fold Stratified Cross-Validation\n",
    "    n_splits = 10\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_idxs, test_idxs in skf.split(X, y):\n",
    "        # Define the training and testing sets\n",
    "        X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "        y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "        \n",
    "        # Initialize the models\n",
    "        rf = RandomForestClassifier(random_state=random_state)\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        # Train the models\n",
    "        rf.fit(X_train, y_train)\n",
    "        dt.fit(X_train, y_train)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the models\n",
    "        results_rf = rf.score(X_test, y_test)\n",
    "        results_dt = dt.score(X_test, y_test)\n",
    "        results_knn = knn.score(X_test, y_test)  \n",
    "        \n",
    "        # Add the results to the running mean\n",
    "        mean_rf += results_rf / (n_splits * 1.0)\n",
    "        mean_dt += results_dt / (n_splits * 1.0)\n",
    "        mean_knn += results_knn / (n_splits * 1.0)\n",
    "    \n",
    "    # Push the mean results from all of the splits to the lists\n",
    "    list_rf.append(mean_rf)\n",
    "    list_dt.append(mean_dt)\n",
    "    list_knn.append(mean_knn)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "print('All trainings complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Below are the final results in attempting to replicate Scenario-B's experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File\t\t\t\t\tRandomForest\tDecision Tree\tk-Nearest Neighbor\n",
      "----------------------------------------------------------------------------------\n",
      "TimeBasedFeatures-15s-Layer2.csv\t83.75%\t\t78.87%\t\t71.22%\n",
      "TimeBasedFeatures-30s-Layer2.csv\t81.48%\t\t77.20%\t\t67.28%\n",
      "TimeBasedFeatures-60s-Layer2.csv\t80.14%\t\t75.97%\t\t62.72%\n",
      "TimeBasedFeatures-120s-Layer2.csv\t78.61%\t\t74.07%\t\t62.99%\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print('File\\t\\t\\t\\t\\tRandomForest\\tDecision Tree\\tk-Nearest Neighbor')\n",
    "print('-'*82)\n",
    "for i in range(len(files)):\n",
    "    print('{}\\t{:.2f}%\\t\\t{:.2f}%\\t\\t{:.2f}%'.format(files[i], 100*list_rf[i], 100*list_dt[i], 100*list_knn[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare our results with those from the Arash *et al.* paper...  \n",
    "![Results from Arash *et al.* for Scenario-B](../media/scenariob_paper.png)\n",
    "...we see that our results, once again, line up pretty well with those we are seeing from the previous work. In this circumstance, our `sklearn` models appear to be marginally out-performing the `Weka` models! However, this is not the focus of the research.   \n",
    "\n",
    "Now that we've shown our ability to replicate the models presented in this work, we have the mobility to move on to the main dish, deep learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Arash Habibi Lashkari, Gerard Draper-Gil, Mohammad Saiful Islam Mamun and Ali A. Ghorbani, \"Characterization of Tor Traffic Using Time Based Features\", In the proceeding of the 3rd International Conference on Information System Security and Privacy, SCITEPRESS, Porto, Portugal, 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
