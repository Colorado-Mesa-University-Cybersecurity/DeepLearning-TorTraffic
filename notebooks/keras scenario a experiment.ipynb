{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Deep Learning on Scenario A\n",
    "\n",
    "Here, we will be applying deep neural networks in an to attempt to differentiate between Tor and nonTor data from the ISCXTor2016 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "# keras Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# sklearn Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split data with stratified cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Encoding of classifications\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a few constants to keep track of\n",
    "random_state=1\n",
    "path='../../tor_dataset/Scenario-A/'\n",
    "dep_var = 'class'\n",
    "num_classes=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(filename='', verbose=False):\n",
    "    \"\"\"\n",
    "        This function takes a filename, loads the data into a dataframe, then separates the classification data\n",
    "        \n",
    "        args:\n",
    "            filename => str, path to csv file to be loaded\n",
    "            \n",
    "        returns:\n",
    "            list(X,y) => data, classifications\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Before encoding and splitting:')\n",
    "        print(df.head())\n",
    "    \n",
    "    # Actual data\n",
    "    X = df.loc[:, df.columns != dep_var]\n",
    "    \n",
    "    # Set number of classes we see\n",
    "    num_classes = df[dep_var].nunique()\n",
    "    \n",
    "    # Classifications\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df[dep_var])\n",
    "    \n",
    "    if verbose:\n",
    "        print('Classification encoding:')\n",
    "        for i in range(len(encoder.classes_)):\n",
    "            print('\\t{} => {}'.format(i, encoder.classes_[i]))\n",
    "        \n",
    "        print('After encoding and splitting:')\n",
    "        print('X = ')\n",
    "        print(X.head())\n",
    "        print('\\ny = ')\n",
    "        print(y[:5])\n",
    "    \n",
    "    # X holds the data while y holds the classifications\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for TimeBasedFeatures-15s-TOR-NonTOR.csv...done\n",
      "Training for TimeBasedFeatures-30s-TOR-NonTOR.csv...done\n",
      "Training for TimeBasedFeatures-60s-TOR-NonTOR.csv...done\n",
      "Training for TimeBasedFeatures-120s-TOR-NonTOR.csv...done\n",
      "All trainings complete!\n"
     ]
    }
   ],
   "source": [
    "# All of the data files\n",
    "files=['TimeBasedFeatures-15s-TOR-NonTOR.csv', \n",
    "       'TimeBasedFeatures-30s-TOR-NonTOR.csv', \n",
    "       'TimeBasedFeatures-60s-TOR-NonTOR.csv', \n",
    "       'TimeBasedFeatures-120s-TOR-NonTOR.csv']\n",
    "\n",
    "# Lists for accuracies collected from models\n",
    "list_dummy = []\n",
    "list_dt = []\n",
    "list_knn = []\n",
    "list_dnn = []\n",
    "\n",
    "for file in files:\n",
    "    print('Training for {}...'.format(file), end='')\n",
    "    \n",
    "    # Load in the data\n",
    "    X, y = get_Xy(path + file)\n",
    "    \n",
    "    # Mean accuracies for each model\n",
    "    mean_dummy = 0 # This is the worst kind of dummy\n",
    "    mean_dt = 0\n",
    "    mean_knn = 0\n",
    "    mean_dnn = 0\n",
    "    \n",
    "    # 10-fold Stratified Cross-Validation\n",
    "    n_splits = 10\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_idxs, test_idxs in skf.split(X, y):\n",
    "        # Define the training and testing sets\n",
    "        X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "        y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "        \n",
    "        # Create a different version of the y_train and y_test for the Deep Neural Network\n",
    "        y_train_dnn = to_categorical(y_train, num_classes=num_classes)\n",
    "        y_test_dnn = to_categorical(y_test, num_classes=num_classes)\n",
    "        \n",
    "        # Initialize the sklearn models\n",
    "        dummy = DummyClassifier(strategy='most_frequent')\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        # Deep Neural Network\n",
    "        dnn = Sequential([\n",
    "            Dense(64, input_shape=(23,)),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "        dnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        # Train the models\n",
    "        dummy.fit(X_train, y_train)\n",
    "        dt.fit(X_train, y_train)\n",
    "        knn.fit(X_train, y_train)\n",
    "        dnn.fit(x=X_train, y=y_train_dnn, epochs=1, batch_size=20, verbose=0, validation_data=(X_test, y_test_dnn))\n",
    "        \n",
    "        # Evaluate the models\n",
    "        results_dummy = dummy.score(X_test, y_test)\n",
    "        results_dt = dt.score(X_test, y_test)\n",
    "        results_knn = knn.score(X_test, y_test)  \n",
    "        results_dnn = ( dnn.evaluate(X_test, y_test_dnn, verbose=0) )[1]\n",
    "        \n",
    "        # Add the results to the running mean\n",
    "        mean_dummy += results_dummy / (n_splits * 1.0)\n",
    "        mean_dt += results_dt / (n_splits * 1.0)\n",
    "        mean_knn += results_knn / (n_splits * 1.0)\n",
    "        mean_dnn += results_dnn / (n_splits * 1.0)\n",
    "    \n",
    "    # Push the mean results from all of the splits to the lists\n",
    "    list_dummy.append(mean_dummy)\n",
    "    list_dt.append(mean_dt)\n",
    "    list_knn.append(mean_knn)\n",
    "    list_dnn.append(mean_dnn)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "print('All trainings complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File\t\t\t\t\tDummy\tDecision Tree\tk-Nearest Neighbor\tDeep Neural Network\n",
      "----------------------------------------------------------------------------------\n",
      "TimeBasedFeatures-15s-TOR-NonTOR.csv\t84.99%\t99.91%\t\t99.88%\t\t\t99.90%\n",
      "TimeBasedFeatures-30s-TOR-NonTOR.csv\t89.22%\t99.90%\t\t99.93%\t\t\t98.50%\n",
      "TimeBasedFeatures-60s-TOR-NonTOR.csv\t94.44%\t99.94%\t\t99.91%\t\t\t99.85%\n",
      "TimeBasedFeatures-120s-TOR-NonTOR.csv\t95.82%\t99.96%\t\t99.92%\t\t\t99.85%\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print('File\\t\\t\\t\\t\\tDummy\\tDecision Tree\\tk-Nearest Neighbor\\tDeep Neural Network')\n",
    "print('-'*82)\n",
    "for i in range(len(files)):\n",
    "    print('{}\\t{:.2f}%\\t{:.2f}%\\t\\t{:.2f}%\\t\\t\\t{:.2f}%'.format(files[i], 100*list_dummy[i], 100*list_dt[i], 100*list_knn[i], 100*list_dnn[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
