{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Deep Learning on Scenario B\n",
    "\n",
    "Here, we will be applying deep neural networks in an to attempt to differentiate between Tor traffic types from the ISCXTor2016 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# DataFrame handling\n",
    "import pandas as pd\n",
    "\n",
    "# keras Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# sklearn Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split data with stratified cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Encoding of classifications\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a few constants to keep track of\n",
    "random_state=1\n",
    "path='../../tor_dataset/Scenario-B/'\n",
    "dep_var = 'class'\n",
    "num_classes=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(filename='', verbose=False):\n",
    "    \"\"\"\n",
    "        This function takes a filename, loads the data into a dataframe, then separates the classification data\n",
    "        \n",
    "        args:\n",
    "            filename => str, path to csv file to be loaded\n",
    "            \n",
    "        returns:\n",
    "            list(X,y) => data, classifications\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Before encoding and splitting:')\n",
    "        print(df.head())\n",
    "    \n",
    "    # Actual data\n",
    "    X = df.loc[:, df.columns != dep_var]\n",
    "    \n",
    "    # Set number of classes we see\n",
    "    num_classes = df[dep_var].nunique()\n",
    "    \n",
    "    # Classifications\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df[dep_var])\n",
    "    \n",
    "    if verbose:\n",
    "        print('Classification encoding:')\n",
    "        for i in range(len(encoder.classes_)):\n",
    "            print('\\t{} => {}'.format(i, encoder.classes_[i]))\n",
    "        \n",
    "        print('After encoding and splitting:')\n",
    "        print('X = ')\n",
    "        print(X.head())\n",
    "        print('\\ny = ')\n",
    "        print(y[:5])\n",
    "    \n",
    "    # X holds the data while y holds the classifications\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for TimeBasedFeatures-15s-Layer2.csv...done\n",
      "Training for TimeBasedFeatures-30s-Layer2.csv...done\n",
      "Training for TimeBasedFeatures-60s-Layer2.csv...done\n",
      "Training for TimeBasedFeatures-120s-Layer2.csv...done\n",
      "All trainings complete!\n"
     ]
    }
   ],
   "source": [
    "# All of the data files\n",
    "files=['TimeBasedFeatures-15s-Layer2.csv',\n",
    "      'TimeBasedFeatures-30s-Layer2.csv',\n",
    "      'TimeBasedFeatures-60s-Layer2.csv',\n",
    "      'TimeBasedFeatures-120s-Layer2.csv']\n",
    "\n",
    "# Lists for accuracies collected from models\n",
    "list_rf = []\n",
    "list_dt = []\n",
    "list_knn = []\n",
    "list_dnn = []\n",
    "\n",
    "for file in files:\n",
    "    print('Training for {}...'.format(file), end='')\n",
    "    \n",
    "    # Load in the data\n",
    "    X, y = get_Xy(path + file)\n",
    "    \n",
    "    # Mean accuracies for each model\n",
    "    mean_rf = 0 # This is the worst kind of dummy\n",
    "    mean_dt = 0\n",
    "    mean_knn = 0\n",
    "    mean_dnn = 0\n",
    "    \n",
    "    # 10-fold Stratified Cross-Validation\n",
    "    n_splits = 10\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_idxs, test_idxs in skf.split(X, y):\n",
    "        # Define the training and testing sets\n",
    "        X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "        y_train, y_test = y[train_idxs], y[test_idxs]\n",
    "        \n",
    "        # Create a different version of the y_train and y_test for the Deep Neural Network\n",
    "        y_train_dnn = to_categorical(y_train, num_classes=num_classes)\n",
    "        y_test_dnn = to_categorical(y_test, num_classes=num_classes)\n",
    "        \n",
    "        # Initialize the sklearn models\n",
    "        rf = RandomForestClassifier(random_state=random_state)\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        # Deep Neural Network\n",
    "        dnn = Sequential([\n",
    "            Dense(64, input_shape=(23,)),\n",
    "            Dense(32, activation='sigmoid'),\n",
    "            Dense(8, activation='softmax')\n",
    "        ])\n",
    "        dnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        # Train the models\n",
    "        rf.fit(X_train, y_train)\n",
    "        dt.fit(X_train, y_train)\n",
    "        knn.fit(X_train, y_train)\n",
    "        dnn.fit(x=X_train, y=y_train_dnn, epochs=1, batch_size=20, verbose=0, validation_data=(X_test, y_test_dnn))\n",
    "        \n",
    "        # Evaluate the models\n",
    "        results_rf = rf.score(X_test, y_test)\n",
    "        results_dt = dt.score(X_test, y_test)\n",
    "        results_knn = knn.score(X_test, y_test)  \n",
    "        results_dnn = ( dnn.evaluate(X_test, y_test_dnn, verbose=0) )[1]\n",
    "        \n",
    "        # Add the results to the running mean\n",
    "        mean_rf += results_rf / (n_splits * 1.0)\n",
    "        mean_dt += results_dt / (n_splits * 1.0)\n",
    "        mean_knn += results_knn / (n_splits * 1.0)\n",
    "        mean_dnn += results_dnn / (n_splits * 1.0)\n",
    "    \n",
    "    # Push the mean results from all of the splits to the lists\n",
    "    list_rf.append(mean_rf)\n",
    "    list_dt.append(mean_dt)\n",
    "    list_knn.append(mean_knn)\n",
    "    list_dnn.append(mean_dnn)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "print('All trainings complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File\t\t\t\t\tRandom Forest\tDecision Tree\tk-Nearest Neighbor\tDeep Neural Network\n",
      "----------------------------------------------------------------------------------\n",
      "TimeBasedFeatures-15s-Layer2.csv\t83.75%\t\t78.87%\t\t71.22%\t\t\t48.54%\n",
      "TimeBasedFeatures-30s-Layer2.csv\t81.48%\t\t77.20%\t\t67.28%\t\t\t45.66%\n",
      "TimeBasedFeatures-60s-Layer2.csv\t80.14%\t\t75.97%\t\t62.72%\t\t\t41.10%\n",
      "TimeBasedFeatures-120s-Layer2.csv\t78.61%\t\t74.07%\t\t62.99%\t\t\t29.36%\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print('File\\t\\t\\t\\t\\tRandom Forest\\tDecision Tree\\tk-Nearest Neighbor\\tDeep Neural Network')\n",
    "print('-'*82)\n",
    "for i in range(len(files)):\n",
    "    print('{}\\t{:.2f}%\\t\\t{:.2f}%\\t\\t{:.2f}%\\t\\t\\t{:.2f}%'.format(files[i], 100*list_rf[i], 100*list_dt[i], 100*list_knn[i], 100*list_dnn[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
